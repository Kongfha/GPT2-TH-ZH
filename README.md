# GPT2-TH-ZH
This project aims to create a text-generation model using the GPT-2 architecture that can generate text in two languages - Thai language (TH) and Chinese language (ZH). The following examples illustrate the model's capabilities:

* \<th> ทำไม ฉัน ต้อง ช่วย ? \<zh> 我 何必 帮 那么 多忙 ？  <|endoftext|>
* \<th> เช่น ความคิดถึง \<zh> 比如 ， 怀旧 。 <|endoftext|>
* \<th> ทีนี้ ช่วง การ ลง จอด ของ วิถี โคจร ทั้งหมด คือ เจ็ด ชั่วโมง \<zh> 整个 着陆 过程 花 了 7 个 小时 。 <|endoftext|>

Our goal is to develop a text-generation model that can generate Thai text with its corresponding Chinese translation. The project consists of a model source code and dataset that will be used to train the GPT-2 language model.

The model will be trained to generate text in both Thai and Chinese, with the Thai text being the primary language and the Chinese text being the translation. By achieving this goal, we hope to understand how neural language model works on multi-language corpus.

